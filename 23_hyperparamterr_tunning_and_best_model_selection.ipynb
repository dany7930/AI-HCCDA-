{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the best model with Best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# train test split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# import regression algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "#import grid search cv for cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# import preprocessors\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = sns.load_dataset('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_bill', 'tip', 'sex', 'smoker', 'day', 'time', 'size'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rergression Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features and variables\n",
    "X = df.drop('tip', axis=1)\n",
    "y = df['tip']\n",
    "\n",
    "# label encode categorical variables\n",
    "le = LabelEncoder()\n",
    "X['sex'] = le.fit_transform(X['sex'])\n",
    "X['smoker'] = le.fit_transform(X['smoker'])\n",
    "X['day'] = le.fit_transform(X['day'])\n",
    "X['time'] = le.fit_transform(X['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error for SVR is  0.57\n",
      "Mean Absolute error for LinearRegression is  0.67\n",
      "Mean Absolute error for XGBRegressor is  0.67\n",
      "Mean Absolute error for GradientBoostingRegressor is  0.72\n",
      "Mean Absolute error for KNeighborsRegressor is  0.73\n",
      "Mean Absolute error for RandomForestRegressor is  0.78\n",
      "Mean Absolute error for DecisionTreeRegressor is  0.88\n",
      "CPU times: total: 2.31 s\n",
      "Wall time: 1.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = mean_absolute_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('Mean Absolute error for', f\"{model[0]} is {model[1]: .2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_squared Score SVR is  0.57\n",
      "R_squared Score LinearRegression is  0.44\n",
      "R_squared Score XGBRegressor is  0.41\n",
      "R_squared Score GradientBoostingRegressor is  0.36\n",
      "R_squared Score KNeighborsRegressor is  0.33\n",
      "R_squared Score RandomForestRegressor is  0.22\n",
      "R_squared Score DecisionTreeRegressor is -0.10\n",
      "CPU times: total: 2.08 s\n",
      "Wall time: 874 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = r2_score(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=True)\n",
    "for model in sorted_models:\n",
    "    print('R_squared Score', f\"{model[0]} is {model[1]: .2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared error for SVR is  0.54\n",
      "Mean Squared error for LinearRegression is  0.69\n",
      "Mean Squared error for XGBRegressor is  0.74\n",
      "Mean Squared error for GradientBoostingRegressor is  0.80\n",
      "Mean Squared error for KNeighborsRegressor is  0.84\n",
      "Mean Squared error for RandomForestRegressor is  0.95\n",
      "Mean Squared error for DecisionTreeRegressor is  1.22\n",
      "CPU times: total: 2.5 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# split the data into train and test data with 80% training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Create a dictionaries of list of models to evaluate performance\n",
    "models = { \n",
    "          'LinearRegression' : LinearRegression(),\n",
    "          'SVR' : SVR(),\n",
    "          'DecisionTreeRegressor' : DecisionTreeRegressor(),\n",
    "          'RandomForestRegressor' : RandomForestRegressor(),\n",
    "          'KNeighborsRegressor' : KNeighborsRegressor(),\n",
    "          'GradientBoostingRegressor' : GradientBoostingRegressor(),\n",
    "          'XGBRegressor' : XGBRegressor()          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "model_scores = []\n",
    "for name, model in models.items():\n",
    "    # fit each model from models on training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = model.predict(X_test)\n",
    "    metric = mean_squared_error(y_test, y_pred)\n",
    "    model_scores.append((name, metric))\n",
    "    \n",
    "    # # print the performing metric\n",
    "    # print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    # print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    # print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    # print('\\n')\n",
    "# selecting the best model from all above models with evaluation metrics sorting method\n",
    "sorted_models = sorted(model_scores, key=lambda x: x[1], reverse=False)\n",
    "for model in sorted_models:\n",
    "    print('Mean Squared error for', f\"{model[0]} is {model[1]: .2f}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Assignment:** Find the best model based on each metrics from above mentioned results?  with Diamonds dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = sns.load_dataset('diamonds')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LinearRegression...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 59\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Setup GridSearchCV\u001b[39;00m\n\u001b[32m     58\u001b[39m grid = GridSearchCV(model, params, cv=\u001b[32m5\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mneg_mean_squared_error\u001b[39m\u001b[33m'\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m grid.fit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Get best model\u001b[39;00m\n\u001b[32m     62\u001b[39m best_model = grid.best_estimator_\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression MSE:  0.6948129686287711\n",
      "LinearRegression R2:  0.4441368826121931\n",
      "LinearRegression MAE:  0.6703807496461158\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionaries of list of models to evaluate performance with hyperparameters\n",
    "models = { \n",
    "          'LinearRegression' : (LinearRegression(), {}),\n",
    "          'SVR' : (SVR(), {'kernel': ['rbf', 'poly', 'sigmoid'], 'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'epsilon': [0.1, 0.01, 0.001]}),\n",
    "          'DecisionTreeRegressor' : (DecisionTreeRegressor(), {'max_depth': [None, 5, 10], 'splitter': ['best', 'random']}),\n",
    "          'RandomForestRegressor' : (RandomForestRegressor(), {'n_estimators': [10, 100, 1000], 'max_depth': [None, 5, 10]}),\n",
    "          'KNeighborsRegressor' : (KNeighborsRegressor(), {'n_neighbors': np.arange(3, 100, 2), 'weights': ['uniform', 'distance']}),\n",
    "          'GradientBoostingRegressor' : (GradientBoostingRegressor(), {'loss': ['ls', 'lad', 'huber', 'quantile'], 'n_estimators': [10, 100, 1000]}),\n",
    "          'XGBRegressor' : (XGBRegressor(), {'n_estimators': [10, 100, 1000], 'learning_rate': [0.1, 0.01, 0.001]}),          \n",
    "          }\n",
    "\n",
    "# train and predict each model with evaluation metrics as well making a for loop to iterate over the models\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    # create a pipline\n",
    "    pipeline = GridSearchCV(model, params, cv=5)\n",
    "    \n",
    "    # fit the pipeline\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # make prediction from each model\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "      \n",
    "    # print the performing metric\n",
    "    print(name, 'MSE: ', mean_squared_error(y_test, y_pred))\n",
    "    print(name, 'R2: ', r2_score(y_test, y_pred))\n",
    "    print(name, 'MAE: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: How to get best parameters of each model, write in the for loop among the code, how to get best model out of it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your Code here\n",
    "\n",
    "##############################################################################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training LinearRegression...\n",
      "LinearRegression Best Parameters: {}\n",
      "LinearRegression MSE: 0.1239\n",
      "LinearRegression R2: -0.6208\n",
      "LinearRegression MAE: 0.3165\n",
      "\n",
      "Training SVR...\n",
      "SVR Best Parameters: {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVR MSE: 0.1190\n",
      "SVR R2: -0.5567\n",
      "SVR MAE: 0.3045\n",
      "\n",
      "Training DecisionTree...\n",
      "DecisionTree Best Parameters: {'max_depth': 5, 'min_samples_split': 10}\n",
      "DecisionTree MSE: 0.1536\n",
      "DecisionTree R2: -1.0086\n",
      "DecisionTree MAE: 0.3276\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Best Parameters: {'max_depth': 10, 'n_estimators': 100}\n",
      "RandomForest MSE: 0.1501\n",
      "RandomForest R2: -0.9629\n",
      "RandomForest MAE: 0.3441\n",
      "\n",
      "Training KNN...\n",
      "KNN Best Parameters: {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "KNN MSE: 0.1104\n",
      "KNN R2: -0.4437\n",
      "KNN MAE: 0.2885\n",
      "\n",
      "Training GradientBoosting...\n",
      "GradientBoosting Best Parameters: {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "GradientBoosting MSE: 0.1228\n",
      "GradientBoosting R2: -0.6054\n",
      "GradientBoosting MAE: 0.3037\n",
      "\n",
      "Training XGBoost...\n",
      "XGBoost Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "XGBoost MSE: 0.1202\n",
      "XGBoost R2: -0.5719\n",
      "XGBoost MAE: 0.2998\n",
      "\n",
      "Final Results:\n",
      "              Model                                        Best Params  \\\n",
      "4               KNN           {'n_neighbors': 9, 'weights': 'uniform'}   \n",
      "1               SVR       {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}   \n",
      "6           XGBoost  {'learning_rate': 0.01, 'max_depth': 3, 'n_est...   \n",
      "5  GradientBoosting       {'learning_rate': 0.01, 'n_estimators': 100}   \n",
      "0  LinearRegression                                                 {}   \n",
      "3      RandomForest             {'max_depth': 10, 'n_estimators': 100}   \n",
      "2      DecisionTree          {'max_depth': 5, 'min_samples_split': 10}   \n",
      "\n",
      "        MSE        R2       MAE  \n",
      "4  0.110393 -0.443738  0.288469  \n",
      "1  0.119029 -0.556681  0.304534  \n",
      "6  0.120194 -0.571923  0.299811  \n",
      "5  0.122751 -0.605366  0.303668  \n",
      "0  0.123928 -0.620759  0.316463  \n",
      "3  0.150090 -0.962910  0.344094  \n",
      "2  0.153581 -1.008559  0.327588  \n",
      "\n",
      "Total execution time: 6.28 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Load your data (replace with your actual data loading)\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# X = df.drop('target_column', axis=1)\n",
    "# y = df['target_column']\n",
    "\n",
    "# For demonstration, creating dummy data if real data not available\n",
    "np.random.seed(42)\n",
    "X = pd.DataFrame(np.random.rand(100, 5), columns=[f'feature_{i}' for i in range(5)])\n",
    "y = pd.Series(np.random.rand(100), name='target')\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optional: Scale features if needed\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Enhanced model dictionary with more parameters\n",
    "models = {\n",
    "    'LinearRegression': (LinearRegression(), {}),\n",
    "    'SVR': (SVR(), {\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'C': [0.1, 1, 10],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }),\n",
    "    'DecisionTree': (DecisionTreeRegressor(random_state=42), {\n",
    "        'max_depth': [None, 5, 10, 15],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'RandomForest': (RandomForestRegressor(random_state=42), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [None, 5, 10]\n",
    "    }),\n",
    "    'KNN': (KNeighborsRegressor(), {\n",
    "        'n_neighbors': [3, 5, 7, 9],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    }),\n",
    "    'GradientBoosting': (GradientBoostingRegressor(random_state=42), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    }),\n",
    "    'XGBoost': (XGBRegressor(random_state=42), {\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1]\n",
    "    })\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Setup GridSearchCV\n",
    "    grid = GridSearchCV(model, params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best model\n",
    "    best_model = grid.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Best Params': grid.best_params_,\n",
    "        'MSE': mse,\n",
    "        'R2': r2,\n",
    "        'MAE': mae\n",
    "    })\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"{name} Best Parameters: {grid.best_params_}\")\n",
    "    print(f\"{name} MSE: {mse:.4f}\")\n",
    "    print(f\"{name} R2: {r2:.4f}\")\n",
    "    print(f\"{name} MAE: {mae:.4f}\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nFinal Results:\")\n",
    "print(results_df.sort_values(by='R2', ascending=False))\n",
    "\n",
    "# Print execution time\n",
    "print(f\"\\nTotal execution time: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Add preprocessor inside the pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Find the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training LinearRegression ===\n",
      "Best parameters: {}\n",
      "MSE: 0.1239\n",
      "R2: -0.6208\n",
      "MAE: 0.3165\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n",
      "\n",
      "=== Training SVR ===\n",
      "Best parameters: {'model__C': 0.1, 'model__epsilon': 0.1, 'model__gamma': 'scale', 'model__kernel': 'rbf'}\n",
      "MSE: 0.1190\n",
      "R2: -0.5567\n",
      "MAE: 0.3045\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n",
      "\n",
      "=== Training DecisionTreeRegressor ===\n",
      "Best parameters: {'model__max_depth': 3, 'model__min_samples_split': 10}\n",
      "MSE: 0.1659\n",
      "R2: -1.1702\n",
      "MAE: 0.3558\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n",
      "\n",
      "=== Training RandomForestRegressor ===\n",
      "Best parameters: {'model__max_depth': None, 'model__n_estimators': 100}\n",
      "MSE: 0.1493\n",
      "R2: -0.9531\n",
      "MAE: 0.3424\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n",
      "\n",
      "=== Training KNeighborsRegressor ===\n",
      "Best parameters: {'model__n_neighbors': 15, 'model__weights': 'uniform'}\n",
      "MSE: 0.1042\n",
      "R2: -0.3634\n",
      "MAE: 0.2833\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n",
      "\n",
      "=== Training GradientBoostingRegressor ===\n",
      "Best parameters: {'model__learning_rate': 0.01, 'model__loss': 'huber', 'model__n_estimators': 100}\n",
      "MSE: 0.1249\n",
      "R2: -0.6338\n",
      "MAE: 0.3075\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n",
      "\n",
      "=== Training XGBRegressor ===\n",
      "Best parameters: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 100}\n",
      "MSE: 0.1202\n",
      "R2: -0.5719\n",
      "MAE: 0.2998\n",
      "Warning: Negative R2 score indicates model performs worse than horizontal line\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Preprocessor setup\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric_scaling', StandardScaler(), [0, 1])  # Scale first two columns\n",
    "    ], \n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Updated models dictionary with valid parameters\n",
    "models = { \n",
    "    'LinearRegression': (LinearRegression(), {}),\n",
    "    'SVR': (SVR(), {\n",
    "        'model__kernel': ['rbf', 'linear'],  # Removed problematic kernels\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__gamma': ['scale', 'auto'],  # Better gamma options\n",
    "        'model__epsilon': [0.1, 0.01]\n",
    "    }),\n",
    "    'DecisionTreeRegressor': (DecisionTreeRegressor(random_state=42), {\n",
    "        'model__max_depth': [None, 3, 5, 7],  # More conservative depths\n",
    "        'model__min_samples_split': [2, 5, 10]\n",
    "    }),\n",
    "    'RandomForestRegressor': (RandomForestRegressor(random_state=42), {\n",
    "        'model__n_estimators': [50, 100],  # Reduced options\n",
    "        'model__max_depth': [None, 5, 7]\n",
    "    }),\n",
    "    'KNeighborsRegressor': (KNeighborsRegressor(), {\n",
    "        'model__n_neighbors': list(range(3, 20, 2)),  # Smaller range\n",
    "        'model__weights': ['uniform', 'distance']\n",
    "    }),\n",
    "    'GradientBoostingRegressor': (GradientBoostingRegressor(random_state=42), {\n",
    "        'model__loss': ['squared_error', 'absolute_error', 'huber'],  # Valid losses\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__learning_rate': [0.1, 0.01]\n",
    "    }),\n",
    "    'XGBRegressor': (XGBRegressor(random_state=42), {\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__learning_rate': [0.1, 0.01],\n",
    "        'model__max_depth': [3, 5]\n",
    "    })          \n",
    "}\n",
    "\n",
    "# Training loop with error handling\n",
    "for name, (model, params) in models.items():\n",
    "    print(f\"\\n=== Training {name} ===\")\n",
    "    \n",
    "    try:\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', model)\n",
    "        ])\n",
    "        \n",
    "        grid_search = GridSearchCV(\n",
    "            pipeline, \n",
    "            param_grid=params,\n",
    "            cv=5,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            error_score='raise'  # Will raise errors immediately\n",
    "        )\n",
    "        \n",
    "        grid_search.fit(X_train, y_train)\n",
    "        y_pred = grid_search.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"R2: {r2:.4f}\") \n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "        \n",
    "        # Check for negative R2\n",
    "        if r2 < 0:\n",
    "            print(\"Warning: Negative R2 score indicates model performs worse than horizontal line\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {str(e)}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: Logistic Regression\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n",
      "Classifier: Decision Tree\n",
      "Mean Accuracy: 0.9533333333333335\n",
      "\n",
      "Classifier: Random Forest\n",
      "Mean Accuracy: 0.9600000000000002\n",
      "\n",
      "Classifier: SVM\n",
      "Mean Accuracy: 0.9666666666666668\n",
      "\n",
      "Classifier: KNN\n",
      "Mean Accuracy: 0.9733333333333334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# dont show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Create a dictionary of classifiers to evaluate\n",
    "classifiers = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(),\n",
    "    'KNN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Perform k-fold cross-validation and calculate the mean accuracy\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for name, classifier in classifiers.items():\n",
    "    scores = cross_val_score(classifier, X, y, cv=kfold)\n",
    "    accuracy = np.mean(scores)\n",
    "    print(\"Classifier:\", name)\n",
    "    print(\"Mean Accuracy:\", accuracy)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Main Assignment:**\n",
    "\n",
    "## Write the complete code to select the best Regressor and classifier for the given dataset called diamonds `(if you have a high end machine, you can use the whole dataset, else use the sample dataset provided in the link)` or you can use Tips datset for Regression task and Iris dataset for Classification task.\n",
    "\n",
    "## You have to choose all possible models with their best or possible hyperparameters and compare them with each other and select the best model for the given dataset.\n",
    "\n",
    "## Your code should be complete and explained properly. for layman, each and every step of the code should be commented properly.\n",
    "\n",
    "## You code should also save the best model in the pickle file.\n",
    "\n",
    "## You should also write the code to load the pickle file and use it for prediction. in the last snippet of the code.\n",
    "\n",
    "## Submit your assignment to the discord inbox. (Do not share the link of your notebook, just upload the notebook in the discord inbox). Do not share the notebook in public channels on our discord server.\n",
    "\n",
    "\n",
    "# **Deadline for Submission:**\n",
    "\n",
    "## `29th December before 09:30 pm Pakistan time. (No late submission will be accepted).`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
